{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "\n",
    "# Resources of audio preprocessing functions\n",
    "# https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LJSpeech locally\n",
    "root = pathlib.Path('/Users/lukgar/Desktop/exjobb/datasets')\n",
    "ljspeech = torchaudio.datasets.LJSPEECH(root, download=False)\n",
    "data_loader = DataLoader(ljspeech, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 4th file in data_loader\n",
    "for i, data in enumerate(data_loader):\n",
    "    if i == 3:\n",
    "        break\n",
    "waveform = data[0].squeeze(0)\n",
    "sample_rate = data[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random audio file\n",
    "data = next(iter(data_loader))\n",
    "print(len(data))\n",
    "waveform = data[0]\n",
    "sample_rate = data[1]\n",
    "waveform = waveform.squeeze(0)\n",
    "sample_rate = sample_rate.item()\n",
    "print(waveform.shape)\n",
    "print(sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  if num_channels == 1:\n",
    "    display(Audio(waveform[0], rate=sample_rate))\n",
    "  elif num_channels == 2:\n",
    "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "  else:\n",
    "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "    axes[c].grid(True)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "    if ylim:\n",
    "      axes[c].set_ylim(ylim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase size of figure\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plot_waveform(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "def get_spectrogram(\n",
    "    n_fft = 400,\n",
    "    win_len = None,\n",
    "    hop_len = None,\n",
    "    power = 2.0,\n",
    "):\n",
    "  waveform, _, _, _ = next(iter(data_loader))\n",
    "  spectrogram = T.Spectrogram(\n",
    "      n_fft=n_fft,\n",
    "      win_length=win_len,\n",
    "      hop_length=hop_len,\n",
    "      center=True,\n",
    "      pad_mode=\"reflect\",\n",
    "      power=power,\n",
    "  )\n",
    "  return spectrogram(waveform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import librosa\n",
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Spectrogram (db)')\n",
    "  axs.set_ylabel(ylabel)\n",
    "  axs.set_xlabel('frame')\n",
    "  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "  if xmax:\n",
    "    axs.set_xlim((0, xmax))\n",
    "  fig.colorbar(im, ax=axs)\n",
    "  plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "mel_spectrogram = T.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "\n",
    "melspec = mel_spectrogram(waveform)\n",
    "plot_spectrogram(\n",
    "    melspec[0], title=\"MelSpectrogram - torchaudio\", ylabel='mel freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "plot_waveform(waveform, sample_rate, title=\"Original\")\n",
    "play_audio(waveform, sample_rate)\n",
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "\n",
    "spec = T.Spectrogram(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    ")(waveform)\n",
    "\n",
    "griffin_lim = T.GriffinLim(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    ")\n",
    "waveform_gm = griffin_lim(spec)\n",
    "\n",
    "plot_waveform(waveform_gm, sample_rate, title=\"Reconstructed\")\n",
    "play_audio(waveform_gm, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513, 416])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save waveform_gm to file\n",
    "torchaudio.save(\"waveform_gm.wav\", waveform_gm, sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4379223da8825d70b8c2eb245c1476bc432c86a2a66eb506943eca18af8434f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
