{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist = MNIST('./data', train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(mnist, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Unet                                               [1, 1, 28, 28]            --\n",
       "├─Conv2d: 1-1                                      [1, 18, 28, 28]           900\n",
       "├─Sequential: 1-2                                  [1, 112]                  --\n",
       "│    └─SinusoidalPositionEmbeddings: 2-1           [1, 28]                   --\n",
       "│    └─Linear: 2-2                                 [1, 112]                  3,248\n",
       "│    └─GELU: 2-3                                   [1, 112]                  --\n",
       "│    └─Linear: 2-4                                 [1, 112]                  12,656\n",
       "├─ModuleList: 1-3                                  --                        --\n",
       "│    └─ModuleList: 2-5                             --                        47,376\n",
       "├─ResBlock: 1-4                                    [1, 28, 28, 28]           --\n",
       "│    └─Block: 2-6                                  [1, 28, 28, 28]           7,140\n",
       "│    └─Sequential: 2-7                             [1, 28]                   3,164\n",
       "│    └─Block: 2-8                                  [1, 28, 28, 28]           7,140\n",
       "│    └─Identity: 2-9                               [1, 28, 28, 28]           --\n",
       "├─Residual: 1-5                                    [1, 28, 28, 28]           --\n",
       "│    └─PreNorm: 2-10                               [1, 28, 28, 28]           14,420\n",
       "├─ResBlock: 1-6                                    [1, 28, 28, 28]           --\n",
       "│    └─Block: 2-11                                 [1, 28, 28, 28]           7,140\n",
       "│    └─Sequential: 2-12                            [1, 28]                   3,164\n",
       "│    └─Block: 2-13                                 [1, 28, 28, 28]           7,140\n",
       "│    └─Identity: 2-14                              [1, 28, 28, 28]           --\n",
       "├─Sequential: 1-7                                  [1, 1, 28, 28]            --\n",
       "│    └─ResBlock: 2-15                              [1, 28, 28, 28]           14,280\n",
       "│    └─Conv2d: 2-16                                [1, 1, 28, 28]            29\n",
       "====================================================================================================\n",
       "Total params: 127,797\n",
       "Trainable params: 127,797\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 77.26\n",
       "====================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 9.50\n",
       "Params size (MB): 0.51\n",
       "Estimated Total Size (MB): 10.02\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diff_unet import Unet\n",
    "\n",
    "img = next(iter(data_loader))[0]\n",
    "t = torch.randint(0, 100, (batch_size,))\n",
    "\n",
    "batch_size, channels, height, width = img.shape\n",
    "\n",
    "unet = Unet(dim=height,\n",
    "            channels=channels,\n",
    "            dim_mults=(1,),\n",
    "            resnet_block_groups=7,\n",
    "            use_convnext=False)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(unet, [(batch_size, channels, height, width), (batch_size,)], depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out = unet(img, t)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img[0, 0, :, :].detach().numpy());\n",
    "ax[1].imshow(out[0, 0, :, :].detach().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'channels',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'downs',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'final_conv',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'init_conv',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'mid_attn',\n",
       " 'mid_block1',\n",
       " 'mid_block2',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'time_mlp',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'ups',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print unet attributes\n",
    "dir(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 7, 7])\n",
      "torch.Size([18])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112])\n",
      "torch.Size([112, 112])\n",
      "torch.Size([112])\n",
      "torch.Size([28, 112])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 18, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 18, 1, 1])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 112])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([384, 28, 1, 1])\n",
      "torch.Size([28, 128, 1, 1])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 112])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([384, 28, 1, 1])\n",
      "torch.Size([28, 128, 1, 1])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 112])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28, 28, 3, 3])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([28])\n",
      "torch.Size([1, 28, 1, 1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param in unet.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Unet(\n",
      "  (init_conv): Conv2d(1, 18, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (time_mlp): Sequential(\n",
      "    (0): SinusoidalPositionEmbeddings()\n",
      "    (1): Linear(in_features=28, out_features=112, bias=True)\n",
      "    (2): GELU(approximate=none)\n",
      "    (3): Linear(in_features=112, out_features=112, bias=True)\n",
      "  )\n",
      "  (downs): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): ResBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "        )\n",
      "        (block1): Block(\n",
      "          (proj): Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): Block(\n",
      "          (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(18, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "        )\n",
      "        (block1): Block(\n",
      "          (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): Block(\n",
      "          (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Identity()\n",
      "    )\n",
      "  )\n",
      "  (ups): ModuleList()\n",
      "  (mid_block1): ResBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "    )\n",
      "    (block1): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Identity()\n",
      "  )\n",
      "  (mid_attn): Residual(\n",
      "    (fn): PreNorm(\n",
      "      (fn): Attention(\n",
      "        (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (to_out): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (mid_block2): ResBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "    )\n",
      "    (block1): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Identity()\n",
      "  )\n",
      "  (final_conv): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block1): Block(\n",
      "        (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (block2): Block(\n",
      "        (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (res_conv): Identity()\n",
      "    )\n",
      "    (1): Conv2d(28, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "1 Conv2d(1, 18, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "2 Sequential(\n",
      "  (0): SinusoidalPositionEmbeddings()\n",
      "  (1): Linear(in_features=28, out_features=112, bias=True)\n",
      "  (2): GELU(approximate=none)\n",
      "  (3): Linear(in_features=112, out_features=112, bias=True)\n",
      ")\n",
      "3 SinusoidalPositionEmbeddings()\n",
      "4 Linear(in_features=28, out_features=112, bias=True)\n",
      "5 GELU(approximate=none)\n",
      "6 Linear(in_features=112, out_features=112, bias=True)\n",
      "7 ModuleList(\n",
      "  (0): ModuleList(\n",
      "    (0): ResBlock(\n",
      "      (mlp): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "      )\n",
      "      (block1): Block(\n",
      "        (proj): Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (block2): Block(\n",
      "        (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (res_conv): Conv2d(18, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (mlp): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "      )\n",
      "      (block1): Block(\n",
      "        (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (block2): Block(\n",
      "        (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (res_conv): Identity()\n",
      "    )\n",
      "    (2): Residual(\n",
      "      (fn): PreNorm(\n",
      "        (fn): LinearAttention(\n",
      "          (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Identity()\n",
      "  )\n",
      ")\n",
      "8 ModuleList(\n",
      "  (0): ResBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "    )\n",
      "    (block1): Block(\n",
      "      (proj): Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Conv2d(18, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): ResBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "    )\n",
      "    (block1): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Identity()\n",
      "  )\n",
      "  (2): Residual(\n",
      "    (fn): PreNorm(\n",
      "      (fn): LinearAttention(\n",
      "        (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (3): Identity()\n",
      ")\n",
      "9 ResBlock(\n",
      "  (mlp): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "  )\n",
      "  (block1): Block(\n",
      "    (proj): Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (block2): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (res_conv): Conv2d(18, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "10 Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=112, out_features=28, bias=True)\n",
      ")\n",
      "11 SiLU()\n",
      "12 Linear(in_features=112, out_features=28, bias=True)\n",
      "13 Block(\n",
      "  (proj): Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "14 Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "15 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "16 SiLU()\n",
      "17 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "18 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "19 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "20 SiLU()\n",
      "21 Conv2d(18, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "22 ResBlock(\n",
      "  (mlp): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "  )\n",
      "  (block1): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (block2): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (res_conv): Identity()\n",
      ")\n",
      "23 Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=112, out_features=28, bias=True)\n",
      ")\n",
      "24 SiLU()\n",
      "25 Linear(in_features=112, out_features=28, bias=True)\n",
      "26 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "27 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "28 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "29 SiLU()\n",
      "30 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "31 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "32 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "33 SiLU()\n",
      "34 Identity()\n",
      "35 Residual(\n",
      "  (fn): PreNorm(\n",
      "    (fn): LinearAttention(\n",
      "      (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "  )\n",
      ")\n",
      "36 PreNorm(\n",
      "  (fn): LinearAttention(\n",
      "    (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      ")\n",
      "37 LinearAttention(\n",
      "  (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "  )\n",
      ")\n",
      "38 Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "39 Sequential(\n",
      "  (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      ")\n",
      "40 Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "41 GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "42 GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "43 Identity()\n",
      "44 ModuleList()\n",
      "45 ResBlock(\n",
      "  (mlp): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "  )\n",
      "  (block1): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (block2): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (res_conv): Identity()\n",
      ")\n",
      "46 Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=112, out_features=28, bias=True)\n",
      ")\n",
      "47 SiLU()\n",
      "48 Linear(in_features=112, out_features=28, bias=True)\n",
      "49 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "50 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "51 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "52 SiLU()\n",
      "53 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "54 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "55 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "56 SiLU()\n",
      "57 Identity()\n",
      "58 Residual(\n",
      "  (fn): PreNorm(\n",
      "    (fn): Attention(\n",
      "      (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (to_out): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "  )\n",
      ")\n",
      "59 PreNorm(\n",
      "  (fn): Attention(\n",
      "    (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (to_out): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      ")\n",
      "60 Attention(\n",
      "  (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (to_out): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "61 Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "62 Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "63 GroupNorm(1, 28, eps=1e-05, affine=True)\n",
      "64 ResBlock(\n",
      "  (mlp): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=112, out_features=28, bias=True)\n",
      "  )\n",
      "  (block1): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (block2): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (res_conv): Identity()\n",
      ")\n",
      "65 Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=112, out_features=28, bias=True)\n",
      ")\n",
      "66 SiLU()\n",
      "67 Linear(in_features=112, out_features=28, bias=True)\n",
      "68 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "69 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "70 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "71 SiLU()\n",
      "72 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "73 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "74 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "75 SiLU()\n",
      "76 Identity()\n",
      "77 Sequential(\n",
      "  (0): ResBlock(\n",
      "    (block1): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): Block(\n",
      "      (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Identity()\n",
      "  )\n",
      "  (1): Conv2d(28, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "78 ResBlock(\n",
      "  (block1): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (block2): Block(\n",
      "    (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (res_conv): Identity()\n",
      ")\n",
      "79 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "80 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "81 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "82 SiLU()\n",
      "83 Block(\n",
      "  (proj): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm): GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "84 Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "85 GroupNorm(7, 28, eps=1e-05, affine=True)\n",
      "86 SiLU()\n",
      "87 Identity()\n",
      "88 Conv2d(28, 1, kernel_size=(1, 1), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# Check activation saturation\n",
    "# Nonlinearities used: GELU, SiLU (swish), softmax(attention)\n",
    "\n",
    "activs = set()\n",
    "\n",
    "for i, layer in enumerate(unet.modules()):\n",
    "    print(i, layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4379223da8825d70b8c2eb245c1476bc432c86a2a66eb506943eca18af8434f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
